{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Analysis with CountVectorizer for probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.plotly as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/probe.log.1\",sep='\\t',index_col=False,\n",
    "                 header=None,names=['time','comp','handle','level','main','code','line','empty','log_entry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>comp</th>\n",
       "      <th>handle</th>\n",
       "      <th>level</th>\n",
       "      <th>main</th>\n",
       "      <th>code</th>\n",
       "      <th>line</th>\n",
       "      <th>empty</th>\n",
       "      <th>log_entry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-29 18:54:37.284190</td>\n",
       "      <td>probe</td>\n",
       "      <td>main</td>\n",
       "      <td>INFO</td>\n",
       "      <td>Main</td>\n",
       "      <td>statistics_tracker.cc</td>\n",
       "      <td>474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCP_CLOSED_CONNECTIONS_PER_SECOND - 64376687 instances 8746409 samples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-29 18:54:37.284195</td>\n",
       "      <td>probe</td>\n",
       "      <td>main</td>\n",
       "      <td>INFO</td>\n",
       "      <td>Main</td>\n",
       "      <td>statistics_tracker.cc</td>\n",
       "      <td>474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCP_TIMEOUT_CONNECTIONS_PER_SECOND - 2070417 instances 8746409 samples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-29 18:54:37.284202</td>\n",
       "      <td>probe</td>\n",
       "      <td>main</td>\n",
       "      <td>INFO</td>\n",
       "      <td>Main</td>\n",
       "      <td>statistics_tracker.cc</td>\n",
       "      <td>474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCP_CONNECTIONS_AVG_DURATION - 25855995974557 instances 64376687 samples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-29 18:54:37.284208</td>\n",
       "      <td>probe</td>\n",
       "      <td>main</td>\n",
       "      <td>INFO</td>\n",
       "      <td>Main</td>\n",
       "      <td>statistics_tracker.cc</td>\n",
       "      <td>474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCP_ACTIVE_CONNECTIONS_PER_SECONDS - 32491459924 instances 8746409 samples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-29 18:54:37.284213</td>\n",
       "      <td>probe</td>\n",
       "      <td>main</td>\n",
       "      <td>INFO</td>\n",
       "      <td>Main</td>\n",
       "      <td>statistics_tracker.cc</td>\n",
       "      <td>474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UDP_STARTED_FLOWS_PER_SECOND - 95949442 instances 8746409 samples</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time   comp handle level  main  \\\n",
       "0  2019-04-29 18:54:37.284190  probe   main  INFO  Main   \n",
       "1  2019-04-29 18:54:37.284195  probe   main  INFO  Main   \n",
       "2  2019-04-29 18:54:37.284202  probe   main  INFO  Main   \n",
       "3  2019-04-29 18:54:37.284208  probe   main  INFO  Main   \n",
       "4  2019-04-29 18:54:37.284213  probe   main  INFO  Main   \n",
       "\n",
       "                    code  line empty  \\\n",
       "0  statistics_tracker.cc   474   NaN   \n",
       "1  statistics_tracker.cc   474   NaN   \n",
       "2  statistics_tracker.cc   474   NaN   \n",
       "3  statistics_tracker.cc   474   NaN   \n",
       "4  statistics_tracker.cc   474   NaN   \n",
       "\n",
       "                                                                    log_entry  \n",
       "0      TCP_CLOSED_CONNECTIONS_PER_SECOND - 64376687 instances 8746409 samples  \n",
       "1      TCP_TIMEOUT_CONNECTIONS_PER_SECOND - 2070417 instances 8746409 samples  \n",
       "2    TCP_CONNECTIONS_AVG_DURATION - 25855995974557 instances 64376687 samples  \n",
       "3  TCP_ACTIVE_CONNECTIONS_PER_SECONDS - 32491459924 instances 8746409 samples  \n",
       "4           UDP_STARTED_FLOWS_PER_SECOND - 95949442 instances 8746409 samples  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>comp</th>\n",
       "      <th>handle</th>\n",
       "      <th>level</th>\n",
       "      <th>main</th>\n",
       "      <th>code</th>\n",
       "      <th>line</th>\n",
       "      <th>empty</th>\n",
       "      <th>log_entry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, comp, handle, level, main, code, line, empty, log_entry]\n",
       "Index: []"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is any rows with empty log entry column\n",
    "df[df.log_entry.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>code</th>\n",
       "      <th>log_entry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [level, code, log_entry]\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 100 # controls max display\n",
    "df1 = df[df.level != 'INFO']\n",
    "#df1.iloc[:,:9]\n",
    "df1[['level','code','log_entry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instances 11501\n",
      "samples 11493\n",
      "connections 11440\n",
      "rollups 11438\n",
      "processor 11438\n",
      "basic 5720\n",
      "time 5720\n",
      "exported 5720\n",
      "tcp 5720\n",
      "send_to_stitcher 5720\n",
      "marker 5720\n",
      "send 5720\n",
      "sample 5718\n",
      "new 5718\n",
      "bytes 3826\n",
      "allocations 3779\n",
      "ssl 1475\n",
      "64 1410\n",
      "packets 1278\n",
      "total 1207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(df['log_entry'], 20)\n",
    "for word, freq in common_words:\n",
    "    print(word, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollups processor 11438\n",
      "tcp connections 5720\n",
      "send_to_stitcher send 5720\n",
      "processor exported 5720\n",
      "time marker 5720\n",
      "basic connections 5720\n",
      "send time 5720\n",
      "processor new 5718\n",
      "new sample 5718\n",
      "total packets 1207\n",
      "queue size 1136\n",
      "size head 1016\n",
      "statistics for 755\n",
      "for handle 755\n",
      "sessions this 714\n",
      "collector sending 714\n",
      "ssl sessions 714\n",
      "heartbeat reported 714\n",
      "this min 714\n",
      "tds heartbeat 714\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_bigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_bigram(df['log_entry'], 20)\n",
    "for word, freq in common_words:\n",
    "    print(word, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send time marker \t 5720\n",
      "send_to_stitcher send time \t 5720\n",
      "rollups processor exported \t 5720\n",
      "rollups processor new \t 5718\n",
      "processor new sample \t 5718\n",
      "queue size head \t 1016\n",
      "statistics for handle \t 755\n",
      "ssl sessions this \t 714\n",
      "sessions this min \t 714\n",
      "sending tds heartbeat \t 714\n",
      "collector sending tds \t 714\n",
      "tds heartbeat reported \t 714\n",
      "heartbeat reported ssl \t 714\n",
      "reported ssl sessions \t 714\n",
      "ssl collector sending \t 714\n",
      "bytes 64 allocations \t 705\n",
      "64 bytes 64 \t 705\n",
      "tail total packets \t 568\n",
      "head tail total \t 568\n",
      "size head tail \t 568\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_trigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(3, 3)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_trigram(df['log_entry'], 20)\n",
    "for word, freq in common_words:\n",
    "    print(word,\"\\t\",freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
